import lief
import collections
import json
import multiprocessing
import os
import time

import pefile


class CustomError(Exception):
    """自定义异常类型的示例"""

    def __init__(self, message):
        self.message = message
        super().__init__(self.message)


def dictSort(dictionary: dict):
    return dict(sorted(dictionary.items(), key=lambda item: item[1], reverse=True))


def dictFilter(dictionary: dict, threshold: int):
    """
    根据阈值，将dict中value>=threshold的元素保留下来，这是筛选特征的最后一步
    """
    return {key: value for key, value in dictionary.items() if value >= threshold}


def dictUpdate(dictionary: dict, allImports: list):
    s = time.time()
    stringCounts = collections.Counter(allImports)
    for key, value in stringCounts.items():
        dictionary[key] = value
    e = time.time()
    print('dict size:', len(dictionary), ', update time:', round(e - s, 6))


def fileParse(validPath: str):
    s = time.time()
    try:
        result = set()

        # # pefile版本
        # pe = pefile.PE(validPath)
        # for entry in pe.DIRECTORY_ENTRY_IMPORT:
        #     for func in entry.imports:
        #         result.add(func.name.decode())  # 因为result是set类型，所以可以在这里去重

        # lief版本
        importTable = lief.PE.parse(validPath)
        for dll in importTable.imports:
            for func in dll.entries:
                result.add(func.name)  # 因为result是set类型，所以可以在这里去重

        result = list(result)
    except CustomError('Can not extract imports of ' + validPath + ' using \'lief\', return None'):
        return None

    e = time.time()
    print('files name:', validPath, ', unique imports nums:', len(result),
          ', time cost:', round(e - s, 6), ', parsed by process:', os.getpid())

    return result


# 此函数主要是为了实现处理malicious和benign时的代码复用
def classParse(rootPath: str):
    paths = os.listdir(rootPath)

    validPaths = {}
    for path in paths:
        fullPath = os.path.join(rootPath, path)
        validPaths[fullPath] = os.path.getsize(fullPath)
    validPaths = dictSort(validPaths)

    fileParsePool = multiprocessing.Pool(multiprocessing.cpu_count())  # 分配进程数量
    resultAddress = []
    for validPath in validPaths.keys():
        resultAddress.append(fileParsePool.apply_async(fileParse, args=(validPath,)))
    fileParsePool.close()
    fileParsePool.join()

    importsSequence = []
    failure = 0  # 无法提取imports的文件数
    for address in resultAddress:
        result = address.get()
        if result is None:
            failure += 1
            continue
        importsSequence += result
    return [importsSequence, len(validPaths.keys()) - failure]


def main():
    # 多进程版本, step 1:
    # 事实上，对于imports来说，由于不需要计算IG这样与正负样本有关的筛选标准，
    # 所以不需要把正负样本分开放，但为了逻辑统一，以及后续特征提取的便利，还是分开放
    with open("../config.json") as f:
        configs = json.load(f)
    print('Start to select import features by threshold:')
    maliciousPath = configs['malicious_validation_samples_path']  # malicious validation set path
    benignPath = configs['benign_validation_samples_path']  # benign validation set path

    allImports = []
    mal_result = classParse(maliciousPath)
    allImports += mal_result[0]
    maliciousSamples = mal_result[1]  # 恶意样本的数量

    ben_result = classParse(benignPath)
    allImports += ben_result[0]
    benignSamples = ben_result[1]  # 良性样本的数量

    allSamples = maliciousSamples + benignSamples
    print('malicious nums:', maliciousSamples, ', benign nums:', benignSamples, ', total nums:', allSamples)

    # step 2
    importsDict = {}
    dictUpdate(importsDict, allImports)
    # print(stringDict)
    importsDict = dictSort(importsDict)
    # print(stringDict)
    threshold = int(allSamples * 0.01)
    importsDict = dict(
        list(dictFilter(importsDict, threshold).items())[:int(configs["max_features_length"])])  # 过滤条件是>=
    print('Selected dict size:', len(importsDict), importsDict)

    # step 3
    jsonPath = 'feature-frequency-pairs.json'
    if os.path.exists(jsonPath):
        os.remove(jsonPath)
    with open(jsonPath, 'w') as json_file:
        json.dump(importsDict, json_file)  # 应该注意的是，运行多次生成的文件可以是不同，因为IG重复值很多，然后降序排序后的结果不唯一
    print('Selecting import features by threshold ends')
    print()


if __name__ == '__main__':
    main()
