import json
import os
import pathlib
import time
import multiprocessing
import csv

import pefile
from opcodes.opcodeGramSelection import getMD


class CustomError(Exception):
    """自定义异常类型的示例"""

    def __init__(self, message):
        self.message = message
        super().__init__(self.message)


def dictSort(dictionary):
    return dict(sorted(dictionary.items(), key=lambda item: item[1], reverse=True))


def extract_feature(features: list, IDFTable: dict, validPath: str):
    s = time.time()
    try:
        pe = pefile.PE(validPath)  # 加载 PE 文件
        md = getMD(pe)
        opcodeList = []
        for section in pe.sections:
            if not section.IMAGE_SCN_MEM_EXECUTE:  # 如果不可执行那么就检查下一个段
                continue
            section_data = section.get_data()
            section_addr = section.VirtualAddress
            # 反汇编节的内容
            for ins in md.disasm(section_data, section_addr):
                opcodeList.append(ins.mnemonic)
        opcodeSequence = ' '.join(opcodeList)
        featureList = []
        for feature in features:
            TF = opcodeSequence.count(feature) / len(opcodeSequence)  # 计算feature在本opcodeSeq中出现的频数
            IDF = IDFTable[feature]
            TF_IDF = TF * IDF
            featureList.append(TF_IDF)

    # 无法正常反汇编的，意味着特征缺失，那么全置为1
    except CustomError('Can not disassemble ' + validPath + ', fill the features with \'-1\''):
        featureList = [-1] * len(features)

    featureList += [pathlib.Path(validPath).parts[-1]]
    # 在train和validation中，存在malicious和benign目录，可以知晓标签
    # 但是在test中没有这两个目录，即不知道标签，所以无法加上标签
    if pathlib.Path(validPath).parts[-2] == 'malicious':
        featureList += [1]  # 倒数第一列是label
    elif pathlib.Path(validPath).parts[-2] == 'benign':
        featureList += [0]  # 倒数第一列是label

    e = time.time()
    print('Extract:', validPath, ' ends, time cost:', round(e - s, 6))
    return featureList


# 这里的class指的是train阶段的malicious和benign类别，以及test阶段的test类别
def classParse(features: dict, rootPath: str, csvPath: str):
    if os.path.exists(csvPath):
        os.remove(csvPath)
    IDFTable = features
    features = list(features.keys())

    csvStream = open(csvPath, mode='a', newline='')
    csvWriter = csv.writer(csvStream)
    if pathlib.Path(rootPath).parts[-1] != 'test':  # 说明此时是为训练集或验证集提取特征
        csvWriter.writerow(features + ['name'] + ['label'])  # 此处是bug更改位置
        csvStream.close()  # 由于特征提取过程过慢，所以先关闭文件流
        print('feature columns: ', [features[0], features[1], '...', features[-2], features[-1], 'name', 'label'])
    else:  # 说明此时是为测试集提取特征
        csvWriter.writerow(features + ['name'])
        csvStream.close()  # 由于特征提取过程过慢，所以先关闭文件流
        print('feature columns: ', [features[0], features[1], '...', features[-2], features[-1], 'name'])

    validPaths = {}
    for path in os.listdir(rootPath):
        fullPath = os.path.join(rootPath, path)
        validPaths[fullPath] = os.path.getsize(fullPath)
    validPaths = dictSort(validPaths)  # 降序排列

    extractPool = multiprocessing.Pool(multiprocessing.cpu_count())  # 分配进程数量
    csvRows = []
    for validPath in validPaths.keys():
        # extract_feature(features, IDFTable, validPath)
        csvRows.append(extractPool.apply_async(extract_feature, args=(features, IDFTable, validPath)))
    extractPool.close()
    extractPool.join()

    csvStream = open(csvPath, mode='a', newline='')
    csvWriter = csv.writer(csvStream)
    for row in csvRows:
        csvWriter.writerow(row.get())
    csvStream.close()


# 此main只是为了进行调试， 实际调用在Instance中
if __name__ == '__main__':
    # 读入json文件，确定要取的样本特征类型,与以往不同的是，这里读取的是feature-IDF
    # classParse传入的features是字典类型，而不是仅仅作为keys的list
    with open(r"feature-IDF-pairs.json", "r") as f:
        features = json.load(f)

    with open("../config.json") as f:
        configs = json.load(f)

    csvName = configs['opcodeGrams_csv_name']
    feaClass = csvName[:-4]
    # 对于每一个文件，都应该完成features的填充，boolean类型
    print('Start to extract ' + feaClass + ' features for each malicious sample in train set:')
    classParse(features, configs['malicious_train_samples_path'], configs['mal_train_csv_path'] + csvName)
    print()
