import os
import pathlib
import re
import time
import multiprocessing
import csv


def dictSort(dictionary):
    return dict(sorted(dictionary.items(), key=lambda item: item[1], reverse=True))


def extract_feature(features: list, validPath: str):
    s = time.time()
    # 读取任意文件的二进制内容，新适用版本
    with open(validPath, "rb") as f:
        byteHex = f.read().hex()

    featureList = []
    for feature in features:
        featureList.append(0) if re.search(feature, byteHex) is None else featureList.append(1)
    featureList += [pathlib.Path(validPath).parts[-1]]

    # 在train和validation中，存在malicious和benign目录，可以知晓标签
    # 但是在test中没有这两个目录，即不知道标签，所以无法加上标签
    if pathlib.Path(validPath).parts[-2] == 'malicious':
        featureList += [1]  # 倒数第一列是label
    elif pathlib.Path(validPath).parts[-2] == 'benign':
        featureList += [0]  # 倒数第一列是label

    e = time.time()
    print('Extract:', validPath, 'ends, time cost:', round(e - s, 6))
    return featureList


# 这里的class指的是train阶段的malicious和benign类别，以及test阶段的test类别
def classParse(features: list, rootPath: str, csvPath: str):
    if os.path.exists(csvPath):
        os.remove(csvPath)

    csvStream = open(csvPath, mode='a', newline='')
    csvWriter = csv.writer(csvStream)
    if pathlib.Path(rootPath).parts[-1] != 'test':  # 说明此时是为训练集或验证集提取特征
        csvWriter.writerow(features + ['name'] + ['label'])  # 此处是bug更改位置
        csvStream.close()  # 由于特征提取过程过慢，所以先关闭文件流
        print('feature columns: ', [features[0], features[1], '...', features[-2], features[-1], 'name', 'label'])
    else:  # 说明此时是为测试集提取特征
        csvWriter.writerow(features + ['name'])
        csvStream.close()  # 由于特征提取过程过慢，所以先关闭文件流
        print('feature columns: ', [features[0], features[1], '...', features[-2], features[-1], 'name'])

    validPaths = {}
    for path in os.listdir(rootPath):
        fullPath = os.path.join(rootPath, path)
        validPaths[fullPath] = os.path.getsize(fullPath)
    validPaths = dictSort(validPaths)  # 降序排列

    extractPool = multiprocessing.Pool(multiprocessing.cpu_count())  # 分配进程数量
    csvRows = []
    for validPath in validPaths.keys():
        csvRows.append(extractPool.apply_async(extract_feature, args=(features, validPath)))
    extractPool.close()
    extractPool.join()

    csvStream = open(csvPath, mode='a', newline='')
    csvWriter = csv.writer(csvStream)
    for row in csvRows:
        csvWriter.writerow(row.get())
    csvStream.close()
